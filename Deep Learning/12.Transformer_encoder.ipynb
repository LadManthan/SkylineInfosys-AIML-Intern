{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T09:15:01.692894Z","iopub.execute_input":"2026-01-16T09:15:01.693298Z","iopub.status.idle":"2026-01-16T09:15:01.698192Z","shell.execute_reply.started":"2026-01-16T09:15:01.693265Z","shell.execute_reply":"2026-01-16T09:15:01.697193Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Positional Encoding","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, seq_len, d_model, max_len=5000):\n        super().__init__()\n\n        #matrix to hold encodings\n        pos_encoding = torch.zeros(seq_len,d_model)\n\n        position = torch.arange(seq_len).unsqueeze(1).float()\n        dimension = torch.arange(d_model).unsqueeze(0).float()\n\n        #calculate angle rate\n        angle_rate = 1 / (10000**((2*(dimension//2)) / d_model))\n\n        #calculate angle in radians\n        angle_radians = position * angle_rate\n        \n        \n        #sin for even pos and cos for odd pos\n        pos_encoding[:,0::2] = torch.sin(angle_radians[:,0::2])\n        pos_encoding[:,1::2] = torch.cos(angle_radians[:,1::2])\n\n        #store encoding to register\n        self.register_buffer(\"pos_encoding\", pos_encoding)\n\n    def forward(self,x):\n        return x + self.pos_encoding.unsqueeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T09:31:31.835279Z","iopub.execute_input":"2026-01-16T09:31:31.835612Z","iopub.status.idle":"2026-01-16T09:31:31.843584Z","shell.execute_reply.started":"2026-01-16T09:31:31.835583Z","shell.execute_reply":"2026-01-16T09:31:31.842564Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"seq_len = 10\nbatch_size = 2\nd_model = 8\n\nx = torch.zeros(seq_len, batch_size, d_model)\n\npe = PositionalEncoding(seq_len, d_model)\nout = pe(x)\n\nprint(out)\nprint(out.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T11:21:53.460480Z","iopub.execute_input":"2026-01-16T11:21:53.461334Z","iopub.status.idle":"2026-01-16T11:21:53.473706Z","shell.execute_reply.started":"2026-01-16T11:21:53.461299Z","shell.execute_reply":"2026-01-16T11:21:53.472557Z"}},"outputs":[{"name":"stdout","text":"tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           1.0000e+00,  0.0000e+00,  1.0000e+00],\n         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           1.0000e+00,  0.0000e+00,  1.0000e+00]],\n\n        [[ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n           9.9995e-01,  1.0000e-03,  1.0000e+00],\n         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n           9.9995e-01,  1.0000e-03,  1.0000e+00]],\n\n        [[ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n           9.9980e-01,  2.0000e-03,  1.0000e+00],\n         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n           9.9980e-01,  2.0000e-03,  1.0000e+00]],\n\n        [[ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n           9.9955e-01,  3.0000e-03,  1.0000e+00],\n         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n\n        [[-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n           9.9920e-01,  4.0000e-03,  9.9999e-01],\n         [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n           9.9920e-01,  4.0000e-03,  9.9999e-01]],\n\n        [[-9.5892e-01,  2.8366e-01,  4.7943e-01,  8.7758e-01,  4.9979e-02,\n           9.9875e-01,  5.0000e-03,  9.9999e-01],\n         [-9.5892e-01,  2.8366e-01,  4.7943e-01,  8.7758e-01,  4.9979e-02,\n           9.9875e-01,  5.0000e-03,  9.9999e-01]],\n\n        [[-2.7942e-01,  9.6017e-01,  5.6464e-01,  8.2534e-01,  5.9964e-02,\n           9.9820e-01,  6.0000e-03,  9.9998e-01],\n         [-2.7942e-01,  9.6017e-01,  5.6464e-01,  8.2534e-01,  5.9964e-02,\n           9.9820e-01,  6.0000e-03,  9.9998e-01]],\n\n        [[ 6.5699e-01,  7.5390e-01,  6.4422e-01,  7.6484e-01,  6.9943e-02,\n           9.9755e-01,  6.9999e-03,  9.9998e-01],\n         [ 6.5699e-01,  7.5390e-01,  6.4422e-01,  7.6484e-01,  6.9943e-02,\n           9.9755e-01,  6.9999e-03,  9.9998e-01]],\n\n        [[ 9.8936e-01, -1.4550e-01,  7.1736e-01,  6.9671e-01,  7.9915e-02,\n           9.9680e-01,  7.9999e-03,  9.9997e-01],\n         [ 9.8936e-01, -1.4550e-01,  7.1736e-01,  6.9671e-01,  7.9915e-02,\n           9.9680e-01,  7.9999e-03,  9.9997e-01]],\n\n        [[ 4.1212e-01, -9.1113e-01,  7.8333e-01,  6.2161e-01,  8.9879e-02,\n           9.9595e-01,  8.9999e-03,  9.9996e-01],\n         [ 4.1212e-01, -9.1113e-01,  7.8333e-01,  6.2161e-01,  8.9879e-02,\n           9.9595e-01,  8.9999e-03,  9.9996e-01]]])\ntorch.Size([10, 2, 8])\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## Position wise Feed Forward Network","metadata":{}},{"cell_type":"code","source":"class PositionFeedForward(nn.Module):\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super().__init__()\n\n        self.linear1 = nn.Linear(d_model,d_ff)\n        self.linear2 = nn.Linear(d_ff,d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self,x):\n        a = self.linear1(x)\n        b = torch.relu(a)\n        c = self.dropout(b)\n        output = self.linear2(c)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T09:41:20.612060Z","iopub.execute_input":"2026-01-16T09:41:20.612459Z","iopub.status.idle":"2026-01-16T09:41:20.619113Z","shell.execute_reply.started":"2026-01-16T09:41:20.612428Z","shell.execute_reply":"2026-01-16T09:41:20.617855Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"d_model = 512\nd_ff = 2048\n\nx = PositionFeedForward(d_model, d_ff)\nprint(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T10:31:20.070171Z","iopub.execute_input":"2026-01-16T10:31:20.070551Z","iopub.status.idle":"2026-01-16T10:31:20.102456Z","shell.execute_reply.started":"2026-01-16T10:31:20.070522Z","shell.execute_reply":"2026-01-16T10:31:20.101170Z"}},"outputs":[{"name":"stdout","text":"PositionFeedForward(\n  (linear1): Linear(in_features=512, out_features=2048, bias=True)\n  (linear2): Linear(in_features=2048, out_features=512, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Encoder Block","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super().__init__()\n\n        self.self_attn = nn.MultiheadAttention(\n            embed_dim = d_model,\n            num_heads = num_heads,\n            dropout = dropout\n        )\n\n        self.feed_forward = PositionFeedForward(\n            d_model = d_model,\n            d_ff = d_ff,\n            dropout = dropout\n        )\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n\n    def forward(self, x, src_mask=None, src_key_padding_mask=None):\n        #multihead attention\n        attention_output, _ = self.self_attn(\n            x,x,x,\n            attn_mask = src_mask,\n            key_padding_mask = src_key_padding_mask\n        )\n\n        #add & norm\n        x = self.norm1(x + self.dropout1(attention_output))\n\n        #fnn\n        fnn_output = self.feed_forward(x)\n\n        #add & norm\n        x = self.norm2(x + self.dropout2(fnn_output))\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T10:10:20.626545Z","iopub.execute_input":"2026-01-16T10:10:20.626915Z","iopub.status.idle":"2026-01-16T10:10:20.635550Z","shell.execute_reply.started":"2026-01-16T10:10:20.626886Z","shell.execute_reply":"2026-01-16T10:10:20.634380Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Hyperparameters similar to attention is all you need\nd_model = 512\nnum_heads = 8\nd_ff = 2048\nseq_len = 10\nbatch_size = 2\n\n# Dummy input\nx = torch.rand(seq_len, batch_size, d_model)\n\n# Positional Encoding\npos_enc = PositionalEncoding(seq_len,d_model)\nx = pos_enc(x)\n\n# Encoder Block\nencoder_block = Encoder(\n    d_model=d_model,\n    num_heads=num_heads,\n    d_ff=d_ff\n)\n\noutput = encoder_block(x)\n\nprint(\"Output shape:\", output.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T10:10:22.979923Z","iopub.execute_input":"2026-01-16T10:10:22.980295Z","iopub.status.idle":"2026-01-16T10:10:23.040777Z","shell.execute_reply.started":"2026-01-16T10:10:22.980265Z","shell.execute_reply":"2026-01-16T10:10:23.039774Z"}},"outputs":[{"name":"stdout","text":"Output shape: torch.Size([10, 2, 512])\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Encoding a real input sentence","metadata":{}},{"cell_type":"code","source":"input = \"Hello I am Manthan\"\ninput = input.lower()\ntokens = input.split()\n\nvocab = {word : idx for idx, word in enumerate(tokens)}\nprint(\"Vocab : \",vocab)\n\n#convert tokens to indices\nindices = torch.tensor([vocab[word] for word in tokens])\nprint(\"\\nIndices : \",indices,'Shape : ',indices.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T10:53:34.083527Z","iopub.execute_input":"2026-01-16T10:53:34.085101Z","iopub.status.idle":"2026-01-16T10:53:34.092194Z","shell.execute_reply.started":"2026-01-16T10:53:34.085059Z","shell.execute_reply":"2026-01-16T10:53:34.091146Z"}},"outputs":[{"name":"stdout","text":"Vocab :  {'hello': 0, 'i': 1, 'am': 2, 'manthan': 3}\n\nIndices :  tensor([0, 1, 2, 3]) Shape :  torch.Size([4])\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"#embedding layer\nd_model = 512\nembedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim = d_model)\n\nx = embedding(indices)\nprint(x)\nprint(\"Shape : \",x.shape)\n\n#adding batch dimension\nx = x.unsqueeze(1)\nprint(\"\\n\",x.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T10:51:24.335459Z","iopub.execute_input":"2026-01-16T10:51:24.336021Z","iopub.status.idle":"2026-01-16T10:51:24.345811Z","shell.execute_reply.started":"2026-01-16T10:51:24.335944Z","shell.execute_reply":"2026-01-16T10:51:24.344772Z"}},"outputs":[{"name":"stdout","text":"tensor([[ 2.1698,  1.2670,  1.5892,  ..., -0.0500, -0.0358, -0.7772],\n        [ 1.7677, -0.0845,  1.1482,  ...,  2.4763,  1.2870, -0.5611],\n        [ 0.4267, -0.1623, -0.6096,  ...,  1.1848, -0.8349, -0.2594],\n        [ 1.4550,  0.9078, -0.6054,  ...,  1.7620, -0.6409, -0.4972]],\n       grad_fn=<EmbeddingBackward0>)\nShape :  torch.Size([4, 512])\n\n torch.Size([4, 1, 512])\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"#add positional encoding\npos_encoding = PositionalEncoding(seq_len = len(tokens), d_model=d_model)\nx = pos_encoding(x)\n\nprint(x)\nprint(x.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T10:49:01.243482Z","iopub.execute_input":"2026-01-16T10:49:01.243819Z","iopub.status.idle":"2026-01-16T10:49:01.252853Z","shell.execute_reply.started":"2026-01-16T10:49:01.243792Z","shell.execute_reply":"2026-01-16T10:49:01.251671Z"}},"outputs":[{"name":"stdout","text":"tensor([[[-0.0057,  0.8104,  1.3416,  ...,  0.3642,  0.3274,  0.0228]],\n\n        [[ 2.6586,  1.6395,  0.4438,  ...,  0.4102,  0.3660,  0.2786]],\n\n        [[-0.0396, -0.4565,  0.8357,  ..., -0.0144,  0.1524,  1.1747]],\n\n        [[ 0.9491, -1.5035, -0.1848,  ...,  0.6514, -0.8078,  0.7944]]],\n       grad_fn=<AddBackward0>)\ntorch.Size([4, 1, 512])\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"encoder = Encoder(\n    d_model = d_model,\n    num_heads = 8,\n    d_ff = 512\n)\n\noutput = encoder(x)\nprint(x)\nprint(x.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T10:49:56.903603Z","iopub.execute_input":"2026-01-16T10:49:56.903968Z","iopub.status.idle":"2026-01-16T10:49:56.933677Z","shell.execute_reply.started":"2026-01-16T10:49:56.903940Z","shell.execute_reply":"2026-01-16T10:49:56.932259Z"}},"outputs":[{"name":"stdout","text":"tensor([[[-0.0057,  0.8104,  1.3416,  ...,  0.3642,  0.3274,  0.0228]],\n\n        [[ 2.6586,  1.6395,  0.4438,  ...,  0.4102,  0.3660,  0.2786]],\n\n        [[-0.0396, -0.4565,  0.8357,  ..., -0.0144,  0.1524,  1.1747]],\n\n        [[ 0.9491, -1.5035, -0.1848,  ...,  0.6514, -0.8078,  0.7944]]],\n       grad_fn=<AddBackward0>)\ntorch.Size([4, 1, 512])\n","output_type":"stream"}],"execution_count":40}]}