{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Attention(Q,K,V) = softmax[(Q.K')/root(d_k)].V\n\n### Q : Query - what i am looking for\n### K : Key - what others offer\n### V : Value - actual information","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:11:47.478892Z","iopub.execute_input":"2026-01-13T06:11:47.479375Z","iopub.status.idle":"2026-01-13T06:11:47.492166Z","shell.execute_reply.started":"2026-01-13T06:11:47.479338Z","shell.execute_reply":"2026-01-13T06:11:47.490744Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#no. of tokens on sequence\nsequence_len = 4\n\n#embedding dimension\nd_model = 6\n\n#input embeddings\nx = np.random.rand(sequence_len, d_model)\nprint(x)\nprint(f\"\\nShape : {x.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:18:04.119159Z","iopub.execute_input":"2026-01-13T06:18:04.119823Z","iopub.status.idle":"2026-01-13T06:18:04.126581Z","shell.execute_reply.started":"2026-01-13T06:18:04.119796Z","shell.execute_reply":"2026-01-13T06:18:04.125183Z"}},"outputs":[{"name":"stdout","text":"[[0.17255662 0.89046146 0.06302079 0.03716833 0.64381609 0.42415671]\n [0.7584668  0.01282786 0.15122622 0.76686935 0.6354084  0.55138562]\n [0.26860023 0.36041556 0.61510388 0.98132322 0.60854504 0.20268606]\n [0.11323265 0.03067561 0.34282456 0.15616114 0.91740022 0.36762164]]\n\nShape : (4, 6)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Create Q,K,V Matrix","metadata":{}},{"cell_type":"code","source":"#for easy understanding\nd_k = d_model\n\n#creating Q,K,V Matrix\nW_Q = np.random.rand(d_model,d_k)\nW_K = np.random.rand(d_model,d_k)\nW_V = np.random.rand(d_model,d_k)\n\nQ = x @ W_Q\nK = x @ W_K\nV = x @ W_V\n\nprint(f\"\\nQ : \\n{Q} \\nShape : {Q.shape}\")\nprint(f\"\\nK : \\n{K} \\nShape : {K.shape}\")\nprint(f\"\\nV : \\n{V} \\nShape : {V.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:21:57.822729Z","iopub.execute_input":"2026-01-13T06:21:57.823058Z","iopub.status.idle":"2026-01-13T06:21:57.832959Z","shell.execute_reply.started":"2026-01-13T06:21:57.823038Z","shell.execute_reply":"2026-01-13T06:21:57.831306Z"}},"outputs":[{"name":"stdout","text":"\nQ : \n[[0.59006109 1.82351479 1.15275307 0.90101941 1.4495238  0.89537097]\n [1.18709951 2.17988632 0.82164891 1.07656732 1.07170281 1.78281354]\n [0.84124281 2.00528123 1.08753234 1.60723069 1.01350603 2.10906083]\n [0.72427638 1.38246253 0.75056761 0.42002978 0.88752102 1.10903567]] \nShape : (4, 6)\n\nK : \n[[1.20633098 1.22980092 0.81588463 1.65863819 0.81204501 1.21145426]\n [1.8933115  1.09048379 1.28882706 1.86432664 0.67407991 1.16468786]\n [1.41679902 1.59446406 1.56402334 2.15958336 0.90076985 1.15225886]\n [1.20676985 0.83123506 0.60793939 1.36312051 0.29812121 1.05755017]] \nShape : (4, 6)\n\nV : \n[[0.64947696 0.91295107 0.89814051 0.78619879 1.36767371 0.86581651]\n [1.13008024 1.20791083 1.84199164 0.61171709 1.52075456 1.04117954]\n [1.20012526 1.19036717 1.65385169 1.00103916 1.57006017 1.28869889]\n [0.38953295 0.8545175  1.11579888 0.51270912 1.00355198 0.74014679]] \nShape : (4, 6)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Calculate Score - Q.K'","metadata":{}},{"cell_type":"code","source":"print(\"Shape of Q.K' : \")\nprint(f\"{Q.shape} x {K.shape[::-1]} --> (4,4)\")\n\n#calculate score\nscore = Q @ K.T  #K.T as we take the transpose of matrix K\n\nprint(\"\\nScore : \\n\",score)\nprint(\"\\nShape : \",score.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:33:22.294161Z","iopub.execute_input":"2026-01-13T06:33:22.294892Z","iopub.status.idle":"2026-01-13T06:33:22.303070Z","shell.execute_reply.started":"2026-01-13T06:33:22.294863Z","shell.execute_reply":"2026-01-13T06:33:22.301291Z"}},"outputs":[{"name":"stdout","text":"Shape of Q.K' : \n(4, 6) x (6, 4) --> (4,4)\n\nScore : \n [[ 7.65112737  8.29109917  9.82967244  5.5358729 ]\n [ 9.59893547 10.48955096 11.78726702  7.41646968]\n [10.41207232 11.31708706 12.90421514  8.06663468]\n [ 5.94717774  6.51919882  7.38878383  4.48948676]]\n\nShape :  (4, 4)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"## Scale the score - (Q.K')/root(d_k)","metadata":{}},{"cell_type":"code","source":"scaled_score = score/np.sqrt(d_k)\nprint(\"Scaled score : \\n\",scaled_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:33:13.434429Z","iopub.execute_input":"2026-01-13T06:33:13.434722Z","iopub.status.idle":"2026-01-13T06:33:13.440898Z","shell.execute_reply.started":"2026-01-13T06:33:13.434704Z","shell.execute_reply":"2026-01-13T06:33:13.439418Z"}},"outputs":[{"name":"stdout","text":"Scaled score : \n [[3.12355967 3.38482706 4.01294697 2.26001065]\n [3.918749   4.28234125 4.81213161 3.02776107]\n [4.25071072 4.62018145 5.26812377 3.29318982]\n [2.42792515 2.66145177 3.01645837 1.8328253 ]]\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Apply Softmax - softmax[(Q.K')/root(d_k)]","metadata":{}},{"cell_type":"code","source":"def softmax(x):\n    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n    return exp_x/np.exp(np.sum(exp_x, axis=1, keepdims=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:39:24.803758Z","iopub.execute_input":"2026-01-13T06:39:24.804143Z","iopub.status.idle":"2026-01-13T06:39:24.809723Z","shell.execute_reply.started":"2026-01-13T06:39:24.804120Z","shell.execute_reply":"2026-01-13T06:39:24.808670Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"attention_weights = softmax(scaled_score)\n\nprint(f\"Attention Weights : \\n {attention_weights}\")\nprint(\"Shape : \",attention_weights.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:40:36.325550Z","iopub.execute_input":"2026-01-13T06:40:36.326595Z","iopub.status.idle":"2026-01-13T06:40:36.332514Z","shell.execute_reply.started":"2026-01-13T06:40:36.326566Z","shell.execute_reply":"2026-01-13T06:40:36.331375Z"}},"outputs":[{"name":"stdout","text":"Attention Weights : \n [[0.0494322  0.06419141 0.12030009 0.02084373]\n [0.04692134 0.06749576 0.11464669 0.01924949]\n [0.04779503 0.06915791 0.13220249 0.0183458 ]\n [0.04280898 0.05406973 0.07711371 0.02360947]]\nShape :  (4, 4)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"## Weighted sum - W.V","metadata":{}},{"cell_type":"code","source":"attention_output = attention_weights @ V\nprint(f\"Attention Output : \\n{attention_output}\")\nprint(\"Shape : \",attention_output.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:43:57.759894Z","iopub.execute_input":"2026-01-13T06:43:57.760379Z","iopub.status.idle":"2026-01-13T06:43:57.778640Z","shell.execute_reply.started":"2026-01-13T06:43:57.760353Z","shell.execute_reply":"2026-01-13T06:43:57.776805Z"}},"outputs":[{"name":"stdout","text":"Attention Output : \n[[0.25714101 0.28367928 0.38485301 0.20924239 0.37502264 0.280092  ]\n [0.25183866 0.27728644 0.37755578 0.20281303 0.36613764 0.27289299]\n [0.27500159 0.30021742 0.40942847 0.22162739 0.39651703 0.29733531]\n [0.19064936 0.21636225 0.29192253 0.15603038 0.285542   0.21021185]]\nShape :  (4, 6)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"## Full Function for complete process","metadata":{}},{"cell_type":"code","source":"def self_attention(x):\n    d_model = x.shape[1]\n    \n    W_Q = np.random.rand(d_model, d_model)\n    W_K = np.random.rand(d_model, d_model)\n    W_V = np.random.rand(d_model, d_model)\n    \n    Q = x @ W_Q\n    K = x @ W_K\n    V = x @ W_V\n    \n    scores = Q @ K.T\n    scaled_scores = scores / np.sqrt(d_model)\n    \n    attention_weights = softmax(scaled_scores)\n    output = attention_weights @ V\n    \n    return attention_weights,output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:52:52.591593Z","iopub.execute_input":"2026-01-13T06:52:52.591893Z","iopub.status.idle":"2026-01-13T06:52:52.600150Z","shell.execute_reply.started":"2026-01-13T06:52:52.591854Z","shell.execute_reply":"2026-01-13T06:52:52.598171Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"seq_len = 5\nd_model = 8\nx = np.random.rand(seq_len, d_model)\n\nattention_weights, output = self_attention(x)\n\nprint(f\"\\nAttention weights : \\n{attention_weights}\")\nprint(\"Shape : \",attention_weights.shape)\n\nprint(f\"\\nOutput : \\n{output}\")\nprint(\"Shape : \",output.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T06:52:55.117091Z","iopub.execute_input":"2026-01-13T06:52:55.117655Z","iopub.status.idle":"2026-01-13T06:52:55.127259Z","shell.execute_reply.started":"2026-01-13T06:52:55.117628Z","shell.execute_reply":"2026-01-13T06:52:55.125076Z"}},"outputs":[{"name":"stdout","text":"\nAttention weights : \n[[0.20394829 0.0002913  0.0002333  0.04195778 0.07782443]\n [0.13833924 0.00257023 0.00230323 0.05121787 0.07921086]\n [0.12268867 0.00331633 0.00348641 0.049309   0.07861334]\n [0.17799862 0.0007156  0.00064987 0.04528137 0.0825765 ]\n [0.1893703  0.00042724 0.00039155 0.04342552 0.08150722]]\nShape :  (5, 5)\n\nOutput : \n[[0.58595281 0.97859754 0.89114927 0.53737505 0.87462587 0.79174393\n  0.80158687 0.98525222]\n [0.48056743 0.80756989 0.73885692 0.44625451 0.73079305 0.65623331\n  0.6595192  0.80147006]\n [0.44738383 0.75489593 0.6913082  0.41816882 0.68455632 0.61445175\n  0.61554037 0.74625931]\n [0.5485171  0.92042016 0.83964843 0.50723422 0.826052   0.74602764\n  0.75229645 0.9213157 ]\n [0.56539553 0.94742331 0.86359237 0.52146327 0.84854597 0.76734886\n  0.77489202 0.95070465]]\nShape :  (5, 8)\n","output_type":"stream"}],"execution_count":52}]}